# ------------------------------------------------------------------------
# Global Parameters
# ------------------------------------------------------------------------
crs: EPSG:3857 # Coordinate Reference System

images:
  - Greenland26X_22W_Sentinel2_2019-06-03_05.tif
  - Greenland26X_22W_Sentinel2_2019-06-19_20.tif
  - Greenland26X_22W_Sentinel2_2019-07-31_25.tif
  - Greenland26X_22W_Sentinel2_2019-08-25_29.tif

training_data_regions:
  Greenland26X_22W_Sentinel2_2019-06-03_05.tif: [2, 4, 6]
  Greenland26X_22W_Sentinel2_2019-06-19_20.tif: [1, 3, 5]
  Greenland26X_22W_Sentinel2_2019-07-31_25.tif: [2, 4, 6]
  Greenland26X_22W_Sentinel2_2019-08-25_29.tif: [1, 3, 5]

test_data_regions: # Data not included in training data provided
  Greenland26X_22W_Sentinel2_2019-06-03_05.tif: [1, 3, 5]
  Greenland26X_22W_Sentinel2_2019-06-19_20.tif: [2, 4, 6]
  Greenland26X_22W_Sentinel2_2019-07-31_25.tif: [1, 3, 5]
  Greenland26X_22W_Sentinel2_2019-08-25_29.tif: [2, 4, 6]

# ------------------------------------------------------------------------
# Machine Specific Parameters
# ------------------------------------------------------------------------
# Loading of image regions (max 12). Defaults to 1.
prepare_num_workers: 12
# Divided between train and val dataloaders
process_num_workers: 32
# Loading of training + test image regions. Set to 1 per gpu available or less (max 24)
extract_num_workers: 4
# Loading of training image regions (max 12). Defaults to max(cpu count, 12).
evaluate_num_workers: 12

# ------------------------------------------------------------------------
# DVC Pipeline Parameters
# ------------------------------------------------------------------------
prepare:
  # Modify depending on the method used
  method: tiling_ann_simple
  file_path: src/methods/prepare/tiling_ann_simple.py
  out: data/prepared

  default:

  tiling_ann_simple:
    tile_size: 448 # Size of each extracted tile
    tile_overlap: 0.5 # Overlap between tiles
    tile_output_size: 320 # Size of each tile after resizing

preprocess:
  # Modify depending on the method used
  method: generate_dataset
  file_path: src/methods/preprocess/generate_dataset.py
  out: data/preprocessed/

  default:

  generate_dataset:
    metadata_path: data/prepared/metadata.csv
    image_sim_path: data/prepared/similarity_map.csv
    lake_image_ratio: 0.7 # Ratio of lake pixels to non-lake pixels in the dataset
    seed: 412 # Random seed for reproducibility
    img_path: data/prepared/tiles
    ann_path: data/prepared/ann_tiles

process:
  ptl_unet:
    seed: 412
    dataset_path: data/preprocessed/dataset.csv
    split: 1
    batch_size: 32

    acc_grad_batches: 1
    precision: 32-true
    metric_monitor: train_iou_loss
    use_best_ckpt: false
    es_patience: null

    lr: 0.00015
    lr_step_size: 20 # StepLR step size
    lr_gamma: 0.8 # StepLR gamma
    tversky_alpha: 0.4
    tversky_beta: 0.6
    lake_loss_gamma: 0.25 # Weight of Tversky loss
    epochs: 140
    num_workers: 32

extract:
  # Modify depending on the method used
  method: extract_border
  file_path: src/methods/extract/extract_border.py

  extract_border:
    overlap_cnt: 2 # Number of overlapping tiles to predict on
